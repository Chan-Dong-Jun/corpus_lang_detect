{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4698da32-e57e-4e7d-9f5a-ced7cdfa2ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import certifi\n",
    "os.environ[\"REQUESTS_CA_BUNDLE\"] = certifi.where()\n",
    "os.environ[\"SSL_CERT_FILE\"] = certifi.where()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2593aca0-69d9-447d-ad05-e5ccd9f33a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lang parsing \n",
    "import re\n",
    "from lingua import Language, LanguageDetectorBuilder\n",
    "\n",
    "#hf lib\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "#multiprocessing lib\n",
    "import multiprocessing\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f84309a-a8ec-4664-8f50-629a3dec3836",
   "metadata": {},
   "source": [
    "# Detect Chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "936c93cb-472a-4033-9bf1-93d3c0c28f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#detect chinese\n",
    "def contains_chinese_characters(text):\n",
    "    pattern = re.compile(r'[\\u4e00-\\u9fff]+')\n",
    "    return bool(pattern.search(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2a3957-5caa-4bbd-be30-3a6fd930e045",
   "metadata": {},
   "source": [
    "# Get Dataset info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fd75e05-c6e8-4919-b62f-0bf1f4afac04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "befcb6a2b279483ea209ac313d476391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/5534 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First file: hf://datasets/tiiuae/falcon-refinedweb@c735840575b629292b41da8dde11dcd523d4f91c/data/train-00000-of-05534-b8fc5348cbe605a5.parquet\n",
      "Dataset hash: c735840575b629292b41da8dde11dcd523d4f91c\n"
     ]
    }
   ],
   "source": [
    "dataset_info = datasets.load_dataset_builder(\"tiiuae/falcon-refinedweb\")\n",
    "files= dataset_info.config.data_files[\"train\"][0]\n",
    "print(\"First file:\", dataset_info.config.data_files[\"train\"][0])\n",
    "print(\"Dataset hash:\", dataset_info.hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6037095e-7c4f-4138-9b90-6f4219510cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hf://datasets/tiiuae/falcon-refinedweb@c735840575b629292b41da8dde11dcd523d4f91c/data/train-00000-of-05534-b8fc5348cbe605a5.parquet',\n",
       " 'hf://datasets/tiiuae/falcon-refinedweb@c735840575b629292b41da8dde11dcd523d4f91c/data/train-00001-of-05534-9bca3ce859516338.parquet',\n",
       " 'hf://datasets/tiiuae/falcon-refinedweb@c735840575b629292b41da8dde11dcd523d4f91c/data/train-00002-of-05534-01680948bd81de83.parquet']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_2_shards=dataset_info.config.data_files[\"train\"][:3]\n",
    "first_2_shards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac7311ac-c3b1-4020-bd62-a62f525383c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load entire dataset\n",
    "falcon_dataset = load_dataset(\"tiiuae/falcon-refinedweb\", data_files=files, streaming=True)\n",
    "falcon_dataset = falcon_dataset[\"train\"]\n",
    "#falcon_dataset = iter(falcon_dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c73af63-35ad-475c-8f61-9ff643273d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d0f1e61-7e90-4c86-81a6-2caceb0c7ea9",
   "metadata": {},
   "source": [
    "# with preload dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7da6874f-ff22-47d3-9a66-4d00e6f19aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "falcon_dataset1 = load_dataset(\"tiiuae/falcon-refinedweb\", data_files='hf://datasets/tiiuae/falcon-refinedweb@c735840575b629292b41da8dde11dcd523d4f91c/data/train-00000-of-05534-b8fc5348cbe605a5.parquet', streaming=True)\n",
    "falcon_dataset2 = load_dataset(\"tiiuae/falcon-refinedweb\", data_files='hf://datasets/tiiuae/falcon-refinedweb@c735840575b629292b41da8dde11dcd523d4f91c/data/train-00002-of-05534-01680948bd81de83.parquet', streaming=True)\n",
    "two_shards_list = [falcon_dataset1, falcon_dataset2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9729e19b-179a-4d58-b2a6-973fcc0d9379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_corpus_for_multi(shared_list, shard):\n",
    "    text_list = []\n",
    "    falcon_dataset_shard = shard[\"train\"]\n",
    "    for index, row_text in enumerate(falcon_dataset_shard):\n",
    "        if contains_chinese_characters(row_text[\"content\"]):\n",
    "            text_list.append(row_text)\n",
    "    return shared_list.append(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf76c378-5ba1-4bdb-b583-bf6c0bf94c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi(file_list, CPU):\n",
    "    if __name__ == '__main__':\n",
    "        print('Running... Multi')\n",
    "        manager_list = multiprocessing.Manager().list()\n",
    "        processes= []\n",
    "\n",
    "        for shard in file_list:\n",
    "            p = multiprocessing.Process(target= iterate_corpus_for_multi, args=(manager_list, shard))\n",
    "            p.start()\n",
    "            processes.append(p)\n",
    "        ended = False\n",
    "\n",
    "        while not ended:\n",
    "            ended=True\n",
    "            for p in processes:\n",
    "                p.join(15) \n",
    "                if (p.is_alive()):\n",
    "                  ended = False\n",
    "        return manager_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a833b1d-2bbd-4183-8507-57419f4c8c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running... Multi\n"
     ]
    }
   ],
   "source": [
    "%time res = multi(two_shards_list, CPU=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712f69b5-f363-4ae9-a375-61546ee169da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68f7b21e-2cd9-44cb-8ccc-6a06921f1e6a",
   "metadata": {},
   "source": [
    "# Iterate 1 shard template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b5f54fc-7ce9-4aad-ab92-ce65a6d3338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_corpus(shard):\n",
    "    text_list = []\n",
    "    for index, row_text in enumerate(shard):\n",
    "        if contains_chinese_characters(row_text[\"content\"]):\n",
    "            text_list.append(row_text)\n",
    "    return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d9ab53e-45cb-4553-9314-b92deb268efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 10s, sys: 31.7 s, total: 2min 41s\n",
      "Wall time: 8min 58s\n"
     ]
    }
   ],
   "source": [
    "%time test_res = iterate_corpus(iterable_shard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b5dbea1-f3c8-489d-8926-4c512b5d058d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': \"Discover Your Blip. What do you want to watch?\\nToday's song is called Just a Waste of Time. ;Listen to it on MySpace: YouTube: script:...日本語訳＋番組詳細 1293 Friday 3 SeptemberThe Daily English Show\\nThe Daily English Show is the world's first daily online English language show. Produced and presented by Sarah - a New Zealander based in Auckland, New Zealand.\",\n",
       " 'url': 'http://blip.tv/thedailyenglishshow/1293-just-a-waste-of-time-negative-news-scheme-vs-scam-glad-wrap-4102793',\n",
       " 'timestamp': datetime.datetime(2013, 5, 18, 10, 32, 1),\n",
       " 'dump': 'CC-MAIN-2013-20',\n",
       " 'segment': '1368696382261',\n",
       " 'image_urls': []}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27d26e4a-bfb1-4b28-9fd3-fb02fcab36d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "655"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668d82b8-c061-4c8a-b2c7-9047b239f9d4",
   "metadata": {},
   "source": [
    "# 2 SHARDS (DONT TOUCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ead4343-f19b-4b90-9bd8-3ba5091bf042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_corpus_for_multi(shared_list, shard_name):\n",
    "    text_list = []\n",
    "    falcon_dataset_shard = load_dataset(\"tiiuae/falcon-refinedweb\", data_files=shard_name, streaming=True)[\"train\"]\n",
    "    for index, row_text in enumerate(falcon_dataset_shard):\n",
    "        if contains_chinese_characters(row_text[\"content\"]):\n",
    "            text_list.append(row_text)\n",
    "    return shared_list.append(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e4df3de-53ce-453f-b9cb-a7826d1b522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi(file_list, CPU):\n",
    "    if __name__ == '__main__':\n",
    "        print('Running... Multi')\n",
    "        manager_list = multiprocessing.Manager().list()\n",
    "        processes= []\n",
    "\n",
    "        for shard_name in file_list:\n",
    "            p = multiprocessing.Process(target= iterate_corpus_for_multi, args=(manager_list, shard_name))\n",
    "            p.start()\n",
    "            processes.append(p)\n",
    "        ended = False\n",
    "\n",
    "        while not ended:\n",
    "            ended=True\n",
    "            for p in processes:\n",
    "                p.join(15) \n",
    "                if (p.is_alive()):\n",
    "                  ended = False\n",
    "        return manager_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4db861d-5212-47ec-9171-4de020c8a515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running... Multi\n",
      "CPU times: user 46 ms, sys: 37 ms, total: 83 ms\n",
      "Wall time: 10min 36s\n"
     ]
    }
   ],
   "source": [
    "file_list = ['hf://datasets/tiiuae/falcon-refinedweb@c735840575b629292b41da8dde11dcd523d4f91c/data/train-00000-of-05534-b8fc5348cbe605a5.parquet',\n",
    " 'hf://datasets/tiiuae/falcon-refinedweb@c735840575b629292b41da8dde11dcd523d4f91c/data/train-00001-of-05534-9bca3ce859516338.parquet']\n",
    "%time res = multi(file_list, CPU=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ac29ef6-5072-4820-aac5-0b2403633e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "655"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res[:][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e326f104-d165-42eb-8490-2e323750a6bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d340d4d0-e013-4708-93c9-e7a34a2d4192",
   "metadata": {},
   "source": [
    "# 3 SHARDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f20ff9ed-659a-402b-92f0-442cfd17c791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_corpus_for_multi(shared_list, shard_name):\n",
    "    text_list = []\n",
    "    falcon_dataset_shard = load_dataset(\"tiiuae/falcon-refinedweb\", data_files=shard_name, streaming=True)[\"train\"]\n",
    "    for index, row_text in enumerate(falcon_dataset_shard):\n",
    "        if contains_chinese_characters(row_text[\"content\"]):\n",
    "            text_list.append(row_text)\n",
    "    return shared_list.append(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd7b285c-79d6-48aa-86f7-a48801f9f262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi(file_list, CPU):\n",
    "    if __name__ == '__main__':\n",
    "        print('Running... Multi')\n",
    "        manager_list = multiprocessing.Manager().list()\n",
    "        processes= []\n",
    "\n",
    "        for shard_name in file_list:\n",
    "            p = multiprocessing.Process(target= iterate_corpus_for_multi, args=(manager_list, shard_name))\n",
    "            p.start()\n",
    "            processes.append(p)\n",
    "        ended = False\n",
    "\n",
    "        while not ended:\n",
    "            ended=True\n",
    "            for p in processes:\n",
    "                p.join(15) \n",
    "                if (p.is_alive()):\n",
    "                  ended = False\n",
    "        return manager_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1af510e-2bcc-49d1-9ddd-2fdda3ac5608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running... Multi\n",
      "CPU times: user 79.7 ms, sys: 100 ms, total: 180 ms\n",
      "Wall time: 15min 34s\n"
     ]
    }
   ],
   "source": [
    "file_list = ['hf://datasets/tiiuae/falcon-refinedweb@c735840575b629292b41da8dde11dcd523d4f91c/data/train-00000-of-05534-b8fc5348cbe605a5.parquet',\n",
    " 'hf://datasets/tiiuae/falcon-refinedweb@c735840575b629292b41da8dde11dcd523d4f91c/data/train-00001-of-05534-9bca3ce859516338.parquet',\n",
    " 'hf://datasets/tiiuae/falcon-refinedweb@c735840575b629292b41da8dde11dcd523d4f91c/data/train-00002-of-05534-01680948bd81de83.parquet']\n",
    "%time res = multi(file_list, CPU=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf32a98-c91c-4f4a-943a-9580109d1405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eefcc417-9f4c-497a-bda0-f2d0bbb761b3",
   "metadata": {},
   "source": [
    "# MULTISHARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eafdd1b9-a048-46ab-81b4-48d0549f6295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running... Multi\n",
      "CPU times: user 86 ms, sys: 123 ms, total: 209 ms\n",
      "Wall time: 17min 30s\n"
     ]
    }
   ],
   "source": [
    "#vers 1\n",
    "# iterate multiple setup\n",
    "def iterate_corpus_for_multi(shared_list, shard_name):\n",
    "    text_list = []\n",
    "    falcon_dataset_shard = load_dataset(\"tiiuae/falcon-refinedweb\", data_files=shard_name, streaming=True)[\"train\"]\n",
    "    for index, row_text in enumerate(falcon_dataset_shard):\n",
    "        if contains_chinese_characters(row_text[\"content\"]):\n",
    "            text_list.append(row_text)\n",
    "    return shared_list.append(text_list)\n",
    "\n",
    "def multi(file_list, CPU=1):\n",
    "    if __name__ == '__main__':\n",
    "        print('Running... Multi')\n",
    "        manager_list = multiprocessing.Manager().list()\n",
    "        processes= []\n",
    "\n",
    "        for shard_name in file_list:\n",
    "            p = multiprocessing.Process(target= iterate_corpus_for_multi, args=(manager_list, shard_name))\n",
    "            p.start()\n",
    "            processes.append(p)\n",
    "        ended = False\n",
    "\n",
    "        while not ended:\n",
    "            ended=True\n",
    "            for p in processes:\n",
    "                # print(f'{p=}')\n",
    "                p.join(15)  # check every 15 sec\n",
    "                if (p.is_alive()):\n",
    "                  ended = False\n",
    "                # print(f'{p=} {p.is_alive()=}')\n",
    "        return manager_list\n",
    "file_list = ['hf://datasets/tiiuae/falcon-refinedweb@c735840575b629292b41da8dde11dcd523d4f91c/data/train-00000-of-05534-b8fc5348cbe605a5.parquet',\n",
    " 'hf://datasets/tiiuae/falcon-refinedweb@c735840575b629292b41da8dde11dcd523d4f91c/data/train-00001-of-05534-9bca3ce859516338.parquet']\n",
    "%time res = multi(file_list, CPU=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7b1419-39a0-4a1c-ab56-2e4086fb9853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running... Multi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-24:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cdongjun/.local/lib/python3.8/site-packages/urllib3/response.py\", line 712, in _error_catcher\n",
      "    yield\n",
      "  File \"/home/cdongjun/.local/lib/python3.8/site-packages/urllib3/response.py\", line 812, in _raw_read\n",
      "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
      "  File \"/home/cdongjun/.local/lib/python3.8/site-packages/urllib3/response.py\", line 797, in _fp_read\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "  File \"/home/cdongjun/anaconda3/envs/test/lib/python3.8/http/client.py\", line 459, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"/home/cdongjun/anaconda3/envs/test/lib/python3.8/http/client.py\", line 503, in readinto\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"/home/cdongjun/anaconda3/envs/test/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/cdongjun/anaconda3/envs/test/lib/python3.8/ssl.py\", line 1274, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/home/cdongjun/anaconda3/envs/test/lib/python3.8/ssl.py\", line 1132, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cdongjun/.local/lib/python3.8/site-packages/requests/models.py\", line 816, in generate\n",
      "    yield from self.raw.stream(chunk_size, decode_content=True)\n",
      "  File \"/home/cdongjun/.local/lib/python3.8/site-packages/urllib3/response.py\", line 934, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"/home/cdongjun/.local/lib/python3.8/site-packages/urllib3/response.py\", line 877, in read\n",
      "    data = self._raw_read(amt)\n",
      "  File \"/home/cdongjun/.local/lib/python3.8/site-packages/urllib3/response.py\", line 833, in _raw_read\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
      "  File \"/home/cdongjun/anaconda3/envs/test/lib/python3.8/contextlib.py\", line 131, in __exit__\n",
      "    self.gen.throw(type, value, traceback)\n",
      "  File \"/home/cdongjun/.local/lib/python3.8/site-packages/urllib3/response.py\", line 729, in _error_catcher\n",
      "    raise ProtocolError(f\"Connection broken: {e!r}\", e) from e\n",
      "urllib3.exceptions.ProtocolError: (\"Connection broken: ConnectionResetError(104, 'Connection reset by peer')\", ConnectionResetError(104, 'Connection reset by peer'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cdongjun/anaconda3/envs/test/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/cdongjun/anaconda3/envs/test/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_3919287/2584134696.py\", line 24, in iterate_corpus_for_multi\n",
      "    for index, row_text in enumerate(falcon_dataset_shard):\n",
      "  File \"/home/cdongjun/anaconda3/envs/test/lib/python3.8/site-packages/datasets/iterable_dataset.py\", line 1384, in __iter__\n",
      "    for key, example in ex_iterable:\n",
      "  File \"/home/cdongjun/anaconda3/envs/test/lib/python3.8/site-packages/datasets/iterable_dataset.py\", line 282, in __iter__\n",
      "    for key, pa_table in self.generate_tables_fn(**self.kwargs):\n",
      "  File \"/home/cdongjun/anaconda3/envs/test/lib/python3.8/site-packages/datasets/packaged_modules/parquet/parquet.py\", line 87, in _generate_tables\n",
      "    for batch_idx, record_batch in enumerate(\n",
      "  File \"pyarrow/_parquet.pyx\", line 1367, in iter_batches\n",
      "  File \"pyarrow/types.pxi\", line 88, in pyarrow.lib._datatype_to_pep3118\n",
      "  File \"/home/cdongjun/anaconda3/envs/test/lib/python3.8/site-packages/datasets/download/streaming_download_manager.py\", line 341, in read_with_retries\n",
      "    out = read(*args, **kwargs)\n",
      "  File \"/home/cdongjun/anaconda3/envs/test/lib/python3.8/site-packages/fsspec/spec.py\", line 1856, in read\n",
      "    out = self.cache._fetch(self.loc, self.loc + length)\n",
      "  File \"/home/cdongjun/anaconda3/envs/test/lib/python3.8/site-packages/fsspec/caching.py\", line 189, in _fetch\n",
      "    self.cache = self.fetcher(start, end)  # new block replaces old\n",
      "  File \"/home/cdongjun/anaconda3/envs/test/lib/python3.8/site-packages/huggingface_hub/hf_file_system.py\", line 625, in _fetch_range\n",
      "    r = http_backoff(\"GET\", url, headers=headers)\n",
      "  File \"/home/cdongjun/anaconda3/envs/test/lib/python3.8/site-packages/huggingface_hub/utils/_http.py\", line 281, in http_backoff\n",
      "    response = session.request(method=method, url=url, **kwargs)\n",
      "  File \"/home/cdongjun/.local/lib/python3.8/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/cdongjun/.local/lib/python3.8/site-packages/requests/sessions.py\", line 725, in send\n",
      "    history = [resp for resp in gen]\n",
      "  File \"/home/cdongjun/.local/lib/python3.8/site-packages/requests/sessions.py\", line 725, in <listcomp>\n",
      "    history = [resp for resp in gen]\n",
      "  File \"/home/cdongjun/.local/lib/python3.8/site-packages/requests/sessions.py\", line 266, in resolve_redirects\n",
      "    resp = self.send(\n",
      "  File \"/home/cdongjun/.local/lib/python3.8/site-packages/requests/sessions.py\", line 747, in send\n",
      "    r.content\n",
      "  File \"/home/cdongjun/.local/lib/python3.8/site-packages/requests/models.py\", line 899, in content\n",
      "    self._content = b\"\".join(self.iter_content(CONTENT_CHUNK_SIZE)) or b\"\"\n",
      "  File \"/home/cdongjun/.local/lib/python3.8/site-packages/requests/models.py\", line 818, in generate\n",
      "    raise ChunkedEncodingError(e)\n",
      "requests.exceptions.ChunkedEncodingError: (\"Connection broken: ConnectionResetError(104, 'Connection reset by peer')\", ConnectionResetError(104, 'Connection reset by peer'))\n"
     ]
    }
   ],
   "source": [
    "#vers2\n",
    "# iterate multiple setup\n",
    "from datetime import datetime\n",
    "#lang parsing \n",
    "import re\n",
    "from lingua import Language, LanguageDetectorBuilder\n",
    "\n",
    "#hf lib\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "#multiprocessing lib\n",
    "import multiprocessing\n",
    "import gc\n",
    "\n",
    "#detect chinese\n",
    "def contains_chinese_characters(text):\n",
    "    pattern = re.compile(r'[\\u4e00-\\u9fff]+')\n",
    "    return bool(pattern.search(text))\n",
    "\n",
    "def iterate_corpus_for_multi(shared_list, shard_name):\n",
    "    text_list = []\n",
    "    falcon_dataset_shard = load_dataset(\"tiiuae/falcon-refinedweb\", data_files=shard_name, streaming=True)[\"train\"]\n",
    "    for index, row_text in enumerate(falcon_dataset_shard):\n",
    "        if contains_chinese_characters(row_text[\"content\"]):\n",
    "            text_list.append(row_text)\n",
    "    return shared_list.append(text_list)\n",
    "\n",
    "def multi(file_list, CPU=1):\n",
    "    print('Running... Multi')\n",
    "    start_time = datetime.now()\n",
    "    manager_list = multiprocessing.Manager().list()\n",
    "    processes= []\n",
    "\n",
    "    for shard_name in file_list:\n",
    "        p = multiprocessing.Process(target= iterate_corpus_for_multi, args=(manager_list, shard_name))\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "    ended = False\n",
    "\n",
    "    while not ended:\n",
    "        ended=True\n",
    "        for p in processes:\n",
    "            # print(f'{p=}')\n",
    "            p.join(15)  # check every 15 sec\n",
    "            if (p.is_alive()):\n",
    "              ended = False\n",
    "            # print(f'{p=} {p.is_alive()=}')\n",
    "        \n",
    "    return manager_list\n",
    "        \n",
    "\n",
    "        \n",
    "file_list = ['hf://datasets/tiiuae/falcon-refinedweb@c735840575b629292b41da8dde11dcd523d4f91c/data/train-00000-of-05534-b8fc5348cbe605a5.parquet', 'hf://datasets/tiiuae/falcon-refinedweb@c735840575b629292b41da8dde11dcd523d4f91c/data/train-00001-of-05534-9bca3ce859516338.parquet']\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = datetime.now()\n",
    "    res = multi(file_list, CPU=2)\n",
    "    end_time = datetime.now()\n",
    "    print(f'* Start = {start_time}')\n",
    "    print(f'* End   = {end_time}')\n",
    "    time_difference = end_time - start_time\n",
    "    print(f'\\n{time_difference = }')\n",
    "    print(len(res[:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4dcc1f1c-6589-40c3-96cc-667e5fb55f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "548"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res[:][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bbf7a3ad-2379-48a7-8582-51fb4cf2a670",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "falcon_dataset = load_dataset(\"tiiuae/falcon-refinedweb\", data_files=first_2_shards, streaming=True)\n",
    "#falcon_dataset = iter(falcon_dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83f01a34-9039-4dee-9923-5c1f82afc1f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IterableDataset({\n",
       "    features: ['content', 'url', 'timestamp', 'dump', 'segment', 'image_urls'],\n",
       "    n_shards: 2\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falcon_dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7683db5b-f285-49a4-adac-8230434a3183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running... Multi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cdongjun/anaconda3/envs/test/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/cdongjun/anaconda3/envs/test/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "TypeError: iterate_corpus() takes 1 positional argument but 2 were given\n",
      "Process Process-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cdongjun/anaconda3/envs/test/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/cdongjun/anaconda3/envs/test/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "TypeError: iterate_corpus() takes 1 positional argument but 2 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.7 ms, sys: 68.3 ms, total: 93 ms\n",
      "Wall time: 158 ms\n"
     ]
    }
   ],
   "source": [
    "%time a = multi(first_2_shards, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a0ea8aa-16c8-49e2-bb51-35a5333d94f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad9c595-4d00-47ad-9d62-14c30cd08947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66074035-87f8-425e-af52-7d6b905895b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a1a870-40fe-42fb-b7b3-765a3255715a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ce6274-a3d2-4d5e-a486-0a7af26764d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2629c360-b141-4337-af06-3fceb4da7a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1c430264e48440189b6c205c0836e85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/5534 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First file: hf://datasets/tiiuae/falcon-refinedweb@c735840575b629292b41da8dde11dcd523d4f91c/data/train-00000-of-05534-b8fc5348cbe605a5.parquet\n",
      "Dataset hash: c735840575b629292b41da8dde11dcd523d4f91c\n"
     ]
    }
   ],
   "source": [
    "dataset_info = datasets.load_dataset_builder(\"tiiuae/falcon-refinedweb\")\n",
    "files= dataset_info.config.data_files[\"train\"][0]\n",
    "print(\"First file:\", dataset_info.config.data_files[\"train\"][0])\n",
    "print(\"Dataset hash:\", dataset_info.hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "40001de0-2c85-40c1-bac7-a945e78a4fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "files= dataset_info.config.data_files[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a659965-2fde-4f15-9576-75748befd44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "009d017d-3adf-468c-aca7-fb4d2a06a190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def contains_chinese_characters(text):\n",
    "    pattern = re.compile(r'[\\u4e00-\\u9fff]+')\n",
    "    return bool(pattern.search(text))\n",
    "print(contains_chinese_characters(\"abca是\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eb1ca1c4-44d8-4b42-aec3-0e6ceb5839e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_corpus():\n",
    "    text_list = []\n",
    "    for index, content in enumerate\n",
    "            \n",
    "    for index,text in enumerate(range(2)):\n",
    "        temp = next(falcon_dataset)\n",
    "        #content = temp[\"content\"] + temp[\"url\"] + str(temp[\"timestamp\"]) + temp[\"dump\"] + temp[\"segment\"] + str(temp[\"image_urls\"])[1:-1]\n",
    "        #content = temp[\"content\"] \n",
    "        text_list.append([index, temp])\n",
    "        #text_list.append(content)\n",
    "        #print(len(text_list))\n",
    "    print(type(temp))\n",
    "    return text_list\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        a, b = next(generator)\n",
    "    except StopIteration:\n",
    "        break\n",
    "    print(\"a: \", a, \"b: \", b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1cf0dbf6-4be6-4367-ad10-627cb3b633f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0,\n",
       "  {'content': 'Postcards from a Global Trekker: Cape Town, South Africa\\nI had a belated birthday celebration this year, given that my 40th birthday fell on Thanksgiving Day, 2010. While my family did a wonderful job incorporating a mini-celebration for me amongst the usual Turkey Day festivities, I never really did acknowledge the day with very much fanfare. Then six months into my 40th year I found myself presented with the rare opportunity of mixing business with pleasure and a second chance at marking a milestone year with a monumental event. At the coaxing of a colleague and friend, I said yes to taking a trip to a place that (20 years in the making) has been on my dream list of places to see in the world. This October I traveled to Cape Town, South Africa for the 2011 World Congress of the World Federation for Mental Health and below are just a few snapshots of the wonderful experience I had both professionally and personally.\\nEleven days in total, half for the congress and half for exploring, the trip was both nothing and everything I could have imagined and more. The conference renewed in me my passion for medicine and reminded me of the importance and complications involved in addressing mental health issues on the larger world public health scale.\\nAnd my time spent exploring the city of Cape Town and meeting its people was absolutely thrilling. Cape Town is blessed with the most stunning natural geologic beauty but its greatest treasures, in my humble opinion, are found amongst its people, especially its artists. I hope you enjoy below a small glimpse of my attempts at capturing the many beautiful experiences I was lucky enough have during my unforgettable adventure in South Africa.\\nReader Comments',\n",
       "   'url': 'http://3sistersvillage.com/blog/2011/11/9/postcards-from-a-global-trekker-cape-town-south-africa.html',\n",
       "   'timestamp': datetime.datetime(2013, 5, 18, 10, 41, 26),\n",
       "   'dump': 'CC-MAIN-2013-20',\n",
       "   'segment': '1368696382261',\n",
       "   'image_urls': [['/universal/images/transparent.png', 'Date Date'],\n",
       "    ['http://threesistersvillage.squarespace.com/storage/CTSA_collage_4_web-large.jpg?__SQUARESPACE_CACHEVERSION=1320345570650',\n",
       "     None],\n",
       "    ['http://threesistersvillage.squarespace.com/storage/CTSA_collage_6_web-large.jpg?__SQUARESPACE_CACHEVERSION=1320341975155',\n",
       "     None],\n",
       "    ['http://threesistersvillage.squarespace.com/storage/CTSA_collage_1_web-large.jpg?__SQUARESPACE_CACHEVERSION=1320341756261',\n",
       "     None],\n",
       "    ['http://threesistersvillage.squarespace.com/storage/CTSA_collage_2_web-large.jpg?__SQUARESPACE_CACHEVERSION=1320340855787',\n",
       "     None],\n",
       "    ['http://threesistersvillage.squarespace.com/storage/CTSA_collage_5_web-large.jpg?__SQUARESPACE_CACHEVERSION=1320342382339',\n",
       "     None],\n",
       "    ['http://threesistersvillage.squarespace.com/storage/CTSA_collage_3_web-large.jpg?__SQUARESPACE_CACHEVERSION=1320342533160',\n",
       "     None]]}],\n",
       " [1,\n",
       "  {'content': 'Rhonda D. McLaughlin vs Bank of America – Sandusky Woman Sues Bank of America Over “Robo-” Foreclosure\\nSince we are on the subject of BOA today, here is another little gem…\\nSandusky woman sues bank over “robo-” foreclosure\\nA Sandusky woman filed a lawsuit Wednesday claiming the foreclosure of her North Larchmont Drive home was spurred on by “robo-signing,” where bank employees signed affidavits without bothering to review documents.\\nRhonda D. McLaughlin filed her lawsuit against Bank of America, N.A., and Rhonda Weston, a vice president of Bank of America. Fannie Mae and Ohio Attorney General Richard Cordray also are named as defendants in the suit.\\nSandusky attorney Dan McGookey, a foreclosure specialist, is McLaughlin’s attorney.\\nIt may be the first lawsuit filed in the U.S. by a private citizen seeking to undo an already completed foreclosure on grounds that a robo-signer was used, McGookey said.\\nMcLaughlin lived at 1608 North Larchmont Drive in Sandusky when Bank of America foreclosed on the home in 2007.\\nMcLaughlin, still a Sandusky resident, lost the home when Erie County Common Pleas Court Judge Roger Binette granted a motion for summary judgment in 2008.\\nThe summary judgment was based on an affidavit from Weston, who said McLaughlin was in default on her mortgage.\\nBinette has been assigned McLaughlin’s new lawsuit.\\nThe lawsuit alleges Weston was a “robo-signer” who didn’t actually review documents she referred to in her affidavit.\\nThe suit cites news stories that say robo-signers signed thousands of affidavits each month without reviewing the mortgage documents, while banks tried to rush through as many foreclosures as possible.\\nThe lawsuit refers to an Associated Press citing court depositions from a Florida attorney, who said employees at Bank of America and other banks commonly approved phony paperwork.\\n“Until now, only a handful of depositions from robo-signers have come to light,” said the Oct. 12 news story. “But the sheer volume of the new depositions will make it more difficult for financial institutions to argue that robo-signing was an aberrant practice in a handful of rogue back offices.”\\nMcLaughlin’s lawsuit asks for Fannie Mae, now the owner of the North Larchmont Drive home, to give the home back to McLaughlin. It seeks $50,000 in damages and other costs and fees.\\nYou can check out the rest of the report here…\\nAnd you can check out the complaint below…\\n~\\n4closureFraud.org\\n~\\nRhonda D. McLaughlin vs Bank of America\\nI have an “Assignment” of the Security Deed only by MERS to BOA signed and dated May of 2008 and a letter from BOA in May of 2009 which states BOA was “seeking ownership but did not yet possess” an interest in the property and instructions to “get out of the house….”\\nMERS recorded this “Assignment” of the Security Deed ONLY in Sept 2010 and BOA then performed a non judicial sale of the property in October 2010 based on MERS assignment—–not an assignment by the original lender American Home Mortgage.\\nThe President of BOA cannot produce the original note or an assignment of the note by the original lender and foreclosed and took possession of the property without EVER recording anything on the land records here\\nCan you say: “Fraud?” The documents themselves do not “sync” and in GA MERS cannot be a trustee, mortgagee, or act independently of written instructions and said docs recorded…..\\nI am pretty close to filing against BOA and MERS—-American Home Mortgage is defunct—so I don’t know who really owns my property, p note or security deed….\\nThe courts have to rule on these things.\\nPissed Off European ‘Lynch Mob’ Is Coming After Bank Of America\\nyou just made me laugh… I have to read that\\nWESTON could not have been a VP in 2007.\\nI have a document that list ALL BAC “ROBO” SIGNORS on a interoffice memo ( or what looks to be ) whereby\\nRHONDA WESTON WAS NOT certified VP by the CORPORATION until 8/7/2009.\\nThis document could be a get-out-of-jail free card for some people who falsified AFFIDAVITS!\\nMy comments are redacted, this case has that document for BofA ROBO’S. Observation…….how could WESTON have claimed VP before the designation was affirmed by corporate in 2008 over a year before? Why did attorney not provide a “CHAIN OF TITLE ” ?\\nI think this one is in the Barn for Plaintiff! Good Luck!\\ndo you or anyone else have a copy of the paper that she was not certified as a vp. i would love a copy! thanks!!\\nGood posts!!!\\nThis is Foreclosure Terrorism. It seems obvious that the judges are lining their pockets and looking the other way. How do you define treason? Well one way would be to say that anyone, any company, any court, any entity that willfully supports Fraud on a scale as massive as this which actually puts children in the streets is directly involved with these crimes against American Home Owners. I call that treason. Where is the FBI in all of this? They just now started making arrests in a handful of cases. But this has been going on for years. What happened to law in this country? It was bought and paid for by the Wall Street Banksters. Spineless politicians are also lining their pockets to look the other way. It is no coincidence that they can’t seem to find a law to stop any of this. It is not possible that they are that incompetent. There are obviously billions in bribes going to the useless bastards who get a nice house on the hill while putting children in the streets. Stop voting Republican or Democrat. They have demonstrated that they are equally involved. It’s time to clean house. We need Joe American in the White House. A child could run a better country and still have time to play in the sandbox after lunch. J Glenn Lowe – Die Banker Die –\\nAgreed Glenn!!\\nThis is most certainly treason, and should come under the heading of “Crimes Against Humanity”. Neither republican nor democrat is innocent in this mess.\\nThis is very interesting. I’m guessing that she won’t be the last person to try this. And why shouldn’t she? If a bank did not have the proper paper work? If they forged documents? If these “Vice-Presidents” that are attesting to the authenticity of these documents are just poor, temp-employees that are signing because it’s either that or go broke and starve? If all of this “stuff” (that’s the polite word) the banks are using as proof, is all fales, then why should we or the banks just assume that they have the legal right to take anyone’s private property. I get so ANGRY! when I hear paid shills for the banks get on the radio or TV saying that we should just assume that the banks have a right even if they have been caught forging documents and lying to courts of law.',\n",
       "   'url': 'http://4closurefraud.org/2010/10/25/sandusky-woman-sues-bank-of-america-over-robo-foreclosure/',\n",
       "   'timestamp': datetime.datetime(2013, 5, 18, 10, 21, 14),\n",
       "   'dump': 'CC-MAIN-2013-20',\n",
       "   'segment': '1368696382261',\n",
       "   'image_urls': []}]]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterate_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b700223a-ee57-49bc-bf8d-3f71f7b0073c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
